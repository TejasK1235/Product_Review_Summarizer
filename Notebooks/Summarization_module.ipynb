{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "927e29ce-8394-4dc0-8f7c-4b0fcdf2bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kotha\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np, re, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18584b0b-160b-474e-9103-f8e5114ad20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# facebook/bart-large-cnn\n",
    "# mabrouk/amazon-review-summarizer-bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cfa1738-f222-473c-932d-34dcff149120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load summarization model (fine-tuned for product reviews)\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)\n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# Sentence embedding model for extractive selection\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"✅ Models loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8baa360b-c32c-4ea3-9500-594e2eda7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    \"\"\"Split text into clean sentences.\"\"\"\n",
    "    sents = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    sents = [s.strip() for s in sents if len(s.strip()) > 3]\n",
    "    return sents\n",
    "\n",
    "def extract_key_by_embedding(text, top_k=6, diversity=0.7):\n",
    "    sents = split_sentences(text)\n",
    "    if not sents:\n",
    "        return ''\n",
    "    embs = embed_model.encode(sents, convert_to_numpy=True)\n",
    "    centroid = embs.mean(axis=0)\n",
    "    scores = embs.dot(centroid)\n",
    "    selected = []\n",
    "    selected_idx = []\n",
    "\n",
    "    for _ in range(min(top_k, len(sents))):\n",
    "        if not selected:\n",
    "            idx = int(np.argmax(scores))\n",
    "        else:\n",
    "            sim_to_selected = np.max(np.dot(embs, embs[selected_idx].T), axis=1)\n",
    "            mmr = diversity * scores - (1 - diversity) * sim_to_selected\n",
    "            mmr[selected_idx] = -np.inf\n",
    "            idx = int(np.argmax(mmr))\n",
    "        selected_idx.append(idx)\n",
    "        selected.append(sents[idx])\n",
    "\n",
    "    return ' '.join(selected)\n",
    "    \n",
    "def chunk_text(text, tokenizer, max_tokens=800, stride=50):\n",
    "    \"\"\"Split long texts into overlapping chunks within model limits.\"\"\"\n",
    "    toks = tokenizer(text, return_tensors='pt', truncation=False)\n",
    "    input_ids = toks['input_ids'][0].tolist()\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(input_ids):\n",
    "        chunk_ids = input_ids[i:i+max_tokens]\n",
    "        chunks.append(tokenizer.decode(chunk_ids, skip_special_tokens=True))\n",
    "        i += max_tokens - stride\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838a6862-6b9e-4f03-b2e3-1526ad1f2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_reviews(text, summarizer, tokenizer, max_input_tokens=800):\n",
    "    \"\"\"Hybrid extractive-abstractive summarization.\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    sentences = split_sentences(text)\n",
    "    if not sentences:\n",
    "        return \"\"\n",
    "\n",
    "    # Short text → one-shot summarize\n",
    "    if len(sentences) <= 8:\n",
    "        key = extract_key_by_embedding(text, top_k=6)\n",
    "        # summary = summarizer(\n",
    "        #     key,\n",
    "        #     max_length=120,      # was 60\n",
    "        #     min_length=40,       # was 20\n",
    "        #     num_beams=5,         # explore more candidates\n",
    "        #     length_penalty=1.2,  # encourage longer outputs\n",
    "        #     no_repeat_ngram_size=3,\n",
    "        #     early_stopping=False # allow full decoding\n",
    "        # )[0]['summary_text']\n",
    "\n",
    "        input_text = (\n",
    "            \"Write a concise and natural summary in your own words for the following product review:\\n\\n\" + text\n",
    "        )\n",
    "        summary = summarizer(\n",
    "            input_text,\n",
    "            max_length=180,        # slightly longer to avoid truncation\n",
    "            min_length=60,         # ensures some depth\n",
    "            do_sample=True,        # adds diversity\n",
    "            top_k=50,              # diverse token sampling\n",
    "            top_p=0.95,            # nucleus sampling\n",
    "            temperature=0.8,       # softer creativity\n",
    "            repetition_penalty=1.2 # avoids repeated phrases\n",
    "        )[0]['summary_text']\n",
    "        \n",
    "        return summary\n",
    "\n",
    "    # Long text → chunk, summarize each, then summarize all\n",
    "    chunks = chunk_text(text, tokenizer, max_tokens=max_input_tokens)\n",
    "    chunk_summaries = []\n",
    "    for c in chunks:\n",
    "        key = extract_key_by_embedding(c, top_k=6)\n",
    "        # result = summarizer(\n",
    "        #     key,\n",
    "        #     max_length=120,      # was 60\n",
    "        #     min_length=40,       # was 20\n",
    "        #     num_beams=5,         # explore more candidates\n",
    "        #     length_penalty=1.2,  # encourage longer outputs\n",
    "        #     no_repeat_ngram_size=3,\n",
    "        #     early_stopping=False # allow full decoding\n",
    "        # )[0]['summary_text']\n",
    "\n",
    "        input_text = (\n",
    "            \"Write a concise and natural summary in your own words for the following product review:\\n\\n\" + text\n",
    "        )\n",
    "        result = summarizer(\n",
    "            input_text,\n",
    "            max_length=180,        # slightly longer to avoid truncation\n",
    "            min_length=60,         # ensures some depth\n",
    "            do_sample=True,        # adds diversity\n",
    "            top_k=50,              # diverse token sampling\n",
    "            top_p=0.95,            # nucleus sampling\n",
    "            temperature=0.8,       # softer creativity\n",
    "            repetition_penalty=1.2 # avoids repeated phrases\n",
    "        )[0]['summary_text']\n",
    "        \n",
    "        chunk_summaries.append(result)\n",
    "\n",
    "    combined_text = ' '.join(chunk_summaries)\n",
    "    # final_summary = summarizer(\n",
    "    #     key,\n",
    "    #     max_length=120,      # was 60\n",
    "    #     min_length=40,       # was 20\n",
    "    #     num_beams=5,         # explore more candidates\n",
    "    #     length_penalty=1.2,  # encourage longer outputs\n",
    "    #     no_repeat_ngram_size=3,\n",
    "    #     early_stopping=False # allow full decoding\n",
    "    # )[0]['summary_text']\n",
    "\n",
    "    input_text = (\n",
    "        \"Write a concise and natural summary in your own words for the following product review:\\n\\n\" + text\n",
    "    )\n",
    "    final_summary = summarizer(\n",
    "        input_text,\n",
    "        max_length=180,        # slightly longer to avoid truncation\n",
    "        min_length=60,         # ensures some depth\n",
    "        do_sample=True,        # adds diversity\n",
    "        top_k=50,              # diverse token sampling\n",
    "        top_p=0.95,            # nucleus sampling\n",
    "        temperature=0.8,       # softer creativity\n",
    "        repetition_penalty=1.2 # avoids repeated phrases\n",
    "    )[0]['summary_text']\n",
    "    \n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89bfc287-c77f-4988-b5fc-bf4db79cda73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf65dc60-7881-44ec-90b6-3151f0d131e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"grouped_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e4e780-410e-421d-9a8e-8e47ae948162",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mreview_length\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mreview_text\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).apply(\u001b[38;5;28mlen\u001b[39m)\n\u001b[32m      2\u001b[39m df_sorted = df.sort_values(by=\u001b[33m'\u001b[39m\u001b[33mreview_length\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      3\u001b[39m df_sorted[[\u001b[33m'\u001b[39m\u001b[33mparent_asin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mproduct_title\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mreview_length\u001b[39m\u001b[33m'\u001b[39m]].head(\u001b[32m50\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['review_length'] = df['review_text'].astype(str).apply(len)\n",
    "df_sorted = df.sort_values(by='review_length', ascending=False)\n",
    "df_sorted[['parent_asin', 'product_title', 'review_length']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d50c655-a82b-4d09-91c4-b91819be6d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am an avid reader of historical fiction, with the emphasis on the historical rather than the upthrust breast variety. This catastrophe fails at both. I have read many many entries in this genre from the extraordinary to the putrid. Lady of Hay falls somewhere below this last category. As other readers have commented, this book is about 200 pages too long. The author has managed to confuse tedium with suspense by dragging out the conclusion long past the point of reader exhaustion. Ms. Erskine's attempts to interweave the present day plot with historical narrative is a complete failure, as she only manages to disrupt both story lines resulting in a herkyjerky narrative flow that became quite annoying. Compounding the problem, not a single character is the slightest bit sympathetic, and although I began the read with curiosity and interest, I ended feeling frustrated and cheated. There are many red herrings dropped along the way that kept me reading, but I got no satisfaction at the end. Why do we meet everyone's mother? How many literary agents, photographers and editors need to be introduced by their names, only to drop from sight 20 pages later? What about nurse Jeanne's foreshadowing of Matilda's illegitimate daughter ultimately giving her secret away resulting in calamity? Did I miss that scene as I waded through episode after repetitive episode of modern Jo swooning in the rain as she channels Lady Matilda? There are too many superfluous characters, seemingly all of whom are interested in and experienced with past life regression, who I kept expecting would have some role in the overall meaning of this morass, but they never did. Not to mention, most of the players seem good candidates for Alcoholics Anonymous. I cannot recall another novel which features wine, ale, scotch, Pimms and their ilk as the central focus in seemingly every scene. The insane behavior of all principals appeared to be nothing more than the result of years of alcohol poisoning a Medieval Lost Weekend. I became so exasperated with their antics and cruel misdeeds that I actually found myself rooting for them all to be sent to the pokey or a rehab facility.br br This book was a major disappointment in every way. It is short on history and long on artifice. If there were some way to award negative stars, this is the ideal candidate. Save your money. Really, really really good\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a product ID\n",
    "sample_asin = df.iloc[5]['parent_asin']\n",
    "df[df['parent_asin'] == sample_asin].iloc[0]['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b54872e-f2f3-43b3-a2ce-31b0bb1924cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The author has managed to confuse tedium with suspense by dragging out the conclusion long past the point of reader exhaustion. There are too many superfluous characters, seemingly all of whom are interested in and experienced with past life regression. I became so exasperated with their antics and cruel misdeeds that I actually found myself rooting for them all to be sent to the pokey.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summarize_reviews(df[df['parent_asin'] == sample_asin].iloc[0]['review_text'], summarizer, tokenizer)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a33a8c1b-c2eb-4620-8c68-d475ab442754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Kate Kennedy has broken up with her boyfriend and is left without a place to stay. She is in the middle of writing a book and decides to rent an isolated country cottage. Once there she is plagued by mysterious and supernatural events. Out of all of Erskine's books that I have read, I probably enjoyed this one the least. What I've enjoyed in the past was her characters in the present day and their connection or experience with historical characters. Although some of that was present here, it read more like a ghost story than an historical novel.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a product ID\n",
    "sample_asin = df.iloc[6]['parent_asin']\n",
    "df[df['parent_asin'] == sample_asin].iloc[0]['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c22f2d-64a2-43ab-a713-4ac4d16366be",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_reviews(df[df['parent_asin'] == sample_asin].iloc[0]['review_text'], summarizer, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e3fcf30-0461-4ccf-b3af-85eeabe0a4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This whimsical character actorwho Stars in Doctor Who tell's his life's story in morbidly dark humor makingas he adeptly does the nonsensical sound believable. The seriousness of his voice is in contrast to the silliness of his tellng. These events did happen and they were bad, but he tells it as if laughing at these peoplein the face who wronged him those many years ago. Lalla Ward, another playphsyco was the perfect match and now I know why. This making the obsurd sound like normal occurance is always present in the tone of these two's voice of reason. It is a game to them. I was on medication for ten years for making the obsurd sound belevalbeeven though I was kidding, apparently mymoronic doctor thought I was serious.I didn't give him a signal, GD. he said after the lawsuit.. Ha! The reason Americans like Baker so much as Doctor Who is this obsurdity that he portrays in contrast to what we lack so severely in American conservativePC culture. Bill Cosby or Tom Baker, you decide, herbert. This is the audio drama of his tale the he himself reads. Amazon has him listed as editor he is also the author and narrator. The tale starts in the cerca earlymid nineteen fourties relating to a catastrophic fire and then to his life and times with abusive family and friends in his childhood and early adulthood to his career path as actor and as DW and later to the presentI assume 1993 or something. Bazaar, full of bathroom humor and the like of brit comedy even his auntinlaw is not saved from disgrace as Letting the most tremendous fart. This was to be quite frank the most depressing autobiography I have ever read. We read of a sordid life full of selfloathing and bumbling from one insanity to another. No vision. The attempts at humor are so dark to be totally unfunny. I get the feeling Tom wrote this to validate his own selfloathing and in my case it suceeded as I end up disliking this person intensely, not just for his morals and lack of inner strength but for removing my vision of him as a funny talented at times actor.br br Not one for faint hearts and not a book to enjoy. Neither is their any depth, what are described are a series of befuddled mixed up scenes which go nowhere to a answer the question of the title.br br Who is Tom Baker? Answer from this book is an almost continously depressed social inadequate, of negligible talent who somehow has survived despite being totally screwed up by events in his life. Not what I wanted to read.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a product ID\n",
    "sample_asin = df.iloc[7]['parent_asin']\n",
    "df[df['parent_asin'] == sample_asin].iloc[0]['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d4f79d6-eaef-4efc-a2ab-83263fb248a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This was to be quite frank the most depressing autobiography I have ever read. We read of a sordid life full of selfloathing and bumbling from one insanity to another. The attempts at humor are so dark to be totally unfunny. Neither is their any depth, what are described are a series of befuddled mixed up scenes which go nowhere to a answer the question of the title.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summarize_reviews(df[df['parent_asin'] == sample_asin].iloc[0]['review_text'], summarizer, tokenizer)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b19daa-3394-45ec-8b3e-988946bcaa4a",
   "metadata": {},
   "source": [
    "# Improving the abstractive part of summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf91d42-7dcd-4468-bb35-d30c89224bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a product ID\n",
    "sample_asin = df.iloc[57]['parent_asin']\n",
    "df[df['parent_asin'] == sample_asin].iloc[0]['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e0cd8-e26e-4e7b-aff2-32a56752b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_reviews(df[df['parent_asin'] == sample_asin].iloc[0]['review_text'], summarizer, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85927346-856f-4b5f-ad9b-50f3bdf6e4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bb4d9d0-fb1e-44aa-9401-c9c08c754175",
   "metadata": {},
   "source": [
    "# Pros and cons generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb1a643-ba14-434e-bebd-1c0528098367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load a lightweight sentiment-analysis model\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "def extract_pros_cons_transformer(summary):\n",
    "    \"\"\"\n",
    "    Extract pros and cons using a transformer sentiment model.\n",
    "    Handles negations and context better than TextBlob.\n",
    "    \"\"\"\n",
    "    pros, cons = [], []\n",
    "\n",
    "    # Split into sentences\n",
    "    sentences = re.split(r'(?<=[.!?]) +', summary)\n",
    "\n",
    "    for sent in sentences:\n",
    "        if not sent.strip():\n",
    "            continue\n",
    "        result = sentiment_analyzer(sent.strip())[0]  # returns {'label': 'POSITIVE', 'score': 0.99}\n",
    "        label = result['label']\n",
    "        \n",
    "        if label == \"POSITIVE\":\n",
    "            pros.append(sent.strip())\n",
    "        else:\n",
    "            cons.append(sent.strip())\n",
    "\n",
    "    # If still empty, mark as neutral\n",
    "    if not pros and not cons:\n",
    "        pros.append(\"No clear positive points detected.\")\n",
    "        cons.append(\"No clear negative points detected.\")\n",
    "\n",
    "    return pros, cons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb8ac128-74b6-404d-90a0-8ad1f4caa1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I enjoyed this book very much. It is a feel good story and perfect for holiday reading. Jenny and her daughter April move into the local coffee shop cottage. She has split up with her cheating husband and has left a very large villa behind. Noah the owner of the coffee shop has given Jenny a job. Jenny and April share the cottage with him and Elle, Noah's friend who works in the coffee shop too. Jenny worries about April because she can't keep her in the style that they used to live in. Can she and her daughter find happiness? Read on. When I picked this up I was expecting a light hearted, easy read. What I got was a heart warming tale of second chances. And I loved it.br The Coffee Club is the best coffee place for miles around, run by Noah and Elle. When Jennys marriage to Zak, the owner of a local fashion house, falls apart after some shocking revelations from the man himself, Jenny finds herself and her 10 yr old daughter April sharing a cottage with the Coffee Club owners. What appears at first glance to be a total comedown complete with public humiliation at leaving a multi millionaire and an 8 bed house to move into a loft conversion where Jenny and April share a room turns into a starting point for a new life, after hitting rock bottom.br This is a story of not only starting over, but finding yourself again. Whether you are a 30 something adult or a 10 yr old child, it's never to late.br We are introduced to such an amazing cast of characters. The author has given them all such depth and are completely relatable. I'd like to say I loved them all, but as with any community, there are some that will grate on you, we can't like everyone, right? And this is testament to the skill of the writer that she can evoke these feelings in the reader and it just makes it all the more believable.br I have to say that I'm finding myself hoping the author has plans to write more stories set in this village. There are a lot of the supporting fringe characters that I feel I'd like to get to know better. And I'd like to revisit this little group to see how their stories progress further down the line. All in all, a superb read with some profound storylines tackling some hard hitting issues. Dealt with in a sympathetic manner and a book that has clearly been well researched. I highly recommend this to everyone.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a product ID\n",
    "sample_asin = df.iloc[57]['parent_asin']\n",
    "df[df['parent_asin'] == sample_asin].iloc[0]['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94170def-44d2-48b3-a26c-0a015780adad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Jenny and her daughter April move into the local coffee shop cottage. She has split up with her cheating husband and has left a very large villa behind. The Coffee Club is the best coffee place for miles around. Jenny and April share the cottage with him and Elle, Noah's friend who works in the coffee shop too.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summarize_reviews(df[df['parent_asin'] == sample_asin].iloc[0]['review_text'], summarizer, tokenizer)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a74394c5-5d55-42c2-a634-ebb04f73769c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I decided to read the book instead of seeing the movie. I should have waited for the movie. There are those works of fiction that make better movies instead of books, this is one of them. The story while interesting was not very compelling. The book offered very little in depth to the true aspect to the emotion of grief. What I thought might be a profound testment to the human heart was really nothing more than a story of grief in the form of total abandonment of her other two children and her own selfishness. I was ready to put it down but after I had invested the time in reading over 200 pages, I trodded along to the end, which left me very unimpressed. The point at which this story ended really should have been it's climax. Like I said I should have waited for the movie.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a product ID\n",
    "sample_asin = df.iloc[62]['parent_asin']\n",
    "df[df['parent_asin'] == sample_asin].iloc[0]['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a0233ee-f532-4053-b6ad-4644992d9eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The book offered very little in depth to the true aspect to the emotion of grief. I was ready to put it down but after I had invested the time in reading over 200 pages, I trodded along to the end, which left me very unimpressed. The point at which this story ended really should have been it's climax.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summarize_reviews(df[df['parent_asin'] == sample_asin].iloc[0]['review_text'], summarizer, tokenizer)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bb426df-cae6-4fec-a33a-f4624059f070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"First, I should say that, unlike many people reading this book, I'd heard about the ending of the series before I even started reading. However, I think that spoiler is allowing me to enjoy the series more than I would have otherwise. Backlash builds the story very slowly. It's not even clear what the larger story arch is about. In retrospect, the Fate of the Jedi series probably takes too long to actually set up the larger threat. As such, much of Backlash might seem pointless. However, knowing what's coming ahead, I can tell you there is a point.br br With that caveat, how is the book? For me, Backlash is where the Fate of the Jedi series began to lose its way. While some of the previous books were a bit slower, they did have some interesting character moments or plot points. I loved the relationship between Luke and Ben in Outcast and Omen. The Mind Walkers provided some great moments through reviving the ghosts of the past.br br By contrast, Backlash takes place primarily on the planet Dathomir and not much seems to happen. Aaron Allston skims over characterization, even to the extent that he leaves major plot holes. For example, Luke and Ben cross paths with Han and Leia and there's barely any reaction! Luke had been exiled for a decade and yet there's little emotion in their reunion. Ben has some great moments in solving puzzles, but Allston almost always ruins them by having somebody state, Well, good thing you trained with the Galactic Alliance Guard, making Ben seem like a onetrick pony.br br The plot also remains bogged down. For an absurdly large part of the book, Luke and Han take part in the Dathomiri equivalent of the olympics. Allana gets kidnaps and escapes from a crazy mechanic, pulling some utterly unbelievable feats, including flying the Falcon. Frankly, I never liked the Solo kids because they always seemed like super kids, and I'd hoped Allana would avoid that fate, but no such luck.. Fortunately, the tension between Daala and the Jedi explodes out into the open. Still, there's not enough there there.br br Overall, I do feel like the Fate of the Jedi series is getting lost. As much as I like seeing the characterization of Luke and Ben, there really isn't much in this book that's worth the price of admission. There's little character development, few action scenes, and the plot stalls. Thus far, this is my least favorite book in the series. I'm crossing my fingers that Allies proves better.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a product ID\n",
    "sample_asin = df.iloc[85]['parent_asin']\n",
    "df[df['parent_asin'] == sample_asin].iloc[0]['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfbe0775-e28e-41e4-963a-d0aff597ddf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Backlash builds the story very slowly. It's not even clear what the larger story arch is about. Aaron Allston skims over characterization, even to the extent that he leaves major plot holes. For an absurdly large part of the book, Luke and Han take part in the Dathomiri equivalent of the olympics.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summarize_reviews(df[df['parent_asin'] == sample_asin].iloc[0]['review_text'], summarizer, tokenizer)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ad552e0-63c3-4620-9544-b51387882c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " ['This was to be quite frank the most depressing autobiography I have ever read.',\n",
       "  'We read of a sordid life full of selfloathing and bumbling from one insanity to another.',\n",
       "  'The attempts at humor are so dark to be totally unfunny.',\n",
       "  'Neither is their any depth, what are described are a series of befuddled mixed up scenes which go nowhere to a answer the question of the title.'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_pros_cons_transformer(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd1f4157-a3e3-4d81-8dd3-f18279f01d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"perhaps the most memorable of the Border Trilogy..Cormac McCarthy takes a little getting used to as far as his literary style but once you find the rhythm of his words sit back and enjoy being transported to a world of masterful prose..John Grady Cole is 16, parents divorced and his grandfather, the only adult he's close to dies then his world changes..deprived of life on his grandfather's ranch after it's sold..he decides to cross the border into Mexico..he's joined on the trip by an old friend, Lacey Rawlins..along the way they meet another teenager, Jimmy Blevins, most likely riding a stolen horse..the three amigos ride into Mexico..and what awaits is a journey that turns them from kids into men..in a harsh Western way..beautifully told...splendid imagery.. I've only just finished Moby Dick before reading ATPH so cryptic style was not a problem, if you follow me, shipmates? I have been aware of Mc Carthy for some time, but have been reluctant to read him, I think due to his artistic reputation. Comparisons to Faulkner aren't enticing, or maybe they are. Anyway, the time was right after Melville. Still, I must say, I liked the story and will read more of this Cormac McCarthy, so mystical and subtle.br br One thing. Does anyone else see a connection with Gabriel's Story by Dunham, another fine book?\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a product ID\n",
    "sample_asin = df.iloc[3]['parent_asin']\n",
    "df[df['parent_asin'] == sample_asin].iloc[0]['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "206740e6-fd7e-4587-9d3a-4663949d5977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cormac McCarthy takes a little getting used to as far as his literary style but once you find the rhythm of his words sit back and enjoy being transported to a world of masterful prose. I've only just finished Moby Dick before reading ATPH so cryptic style was not a problem, if you follow me, shipmates? I have been aware of Mc Carthy for some time, but have been reluctant to read him, I think due to his artistic reputation.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summarize_reviews(df[df['parent_asin'] == sample_asin].iloc[0]['review_text'], summarizer, tokenizer)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33f90357-f65a-4022-ae76-c1329059de3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Cormac McCarthy takes a little getting used to as far as his literary style but once you find the rhythm of his words sit back and enjoy being transported to a world of masterful prose.'],\n",
       " [\"I've only just finished Moby Dick before reading ATPH so cryptic style was not a problem, if you follow me, shipmates?\",\n",
       "  'I have been aware of Mc Carthy for some time, but have been reluctant to read him, I think due to his artistic reputation.'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_pros_cons_transformer(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28385e4-0719-4006-a722-9598a382e206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76862471-4434-4292-bf75-0255e60c9745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdcdc3e-462f-490d-9168-39132a5ccf59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431df5e-2b3c-4186-8d8d-84208d56bb80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
